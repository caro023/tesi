\chapter{TeraFlow: architettura e gestione degli intenti}
\label{cap:teraflow}

Il controller SDN su cui ci focalizzeremo è TeraFlow \cite{TeraFlow}, una piattaforma recentemente proposta, sviluppata da un'ampia comunità open source nell'ambito di un progetto europeo. 
\newline Infatti, è stato finanziato dall'unione europea per il programma di ricerca e innovazione Horizon 2020 \cite{Horizon} e supportato dal 5G PPP \cite{5GPPP}, un'iniziativa congiunta tra la Commissione Europea e l'industria europea delle telecomunicazioni.
%Nonostante la quantità di controller SDN i fondatori di TeraFlow hanno riscontrato che molte delle soluzioni attuali sono costituite da un software monolitoco
%in grado di sincronizzarsi con altri controller SDN distribuiti tramite protocolli specifici.
%Il problema principale dei controller SDN `e il basso numero di contribuzioni che negli ul-timi anni o mesi si stanno sempre di pi`u diradando
\newline Nonostante la quantità di controller SDN i fondatori di TeraFlow hanno riscontrato come problema comune il calo delle contribuzioni ai progetti open source rilevanti negli ultimi anni.
Questo declino mette a rischio il continuo sviluppo e il supporto per i nuovi bisogni delle reti moderne lasciando molte soluzioni esistenti inadeguate per affrontare le sfide emergenti.
\newline L'obiettivo di TeraFlow è implementare un controller SDN Carrier Grade (reti o infrastrutture ben testate con livelli estremamente elevati di affidabilità, ridondanza e sicurezza)
che soddisfi i requisiti attuali ed eventualmente futuri per le reti, sia architetturali che infrastrutturali, e che sia in grado di gestire miliardi di dispositivi.
Il controller mira a migliorare le capacità di elaborazione dei flussi permettendo di gestire un volume di traffico equivalente a un terabit al secondo. 
Questa capacità è cruciale per supportare le elevate esigenze di connettività delle reti B5G (Beyond Fifth Generation).
%TeraFlow è un progetto OpenSource 
%al quale tutti i membri della comunità ETSI (European Telecommunications Standard Institute) \cite{etsi} possono contribuire. 
\newline Un ulteriore obiettivo è ridurre il divario tra le necessità delle industrie e ciò che offrono gli standard SDN.
\newline Questo controller, attualmente in fase di sviluppo, sarà progettato per integrarsi con gli attuali framework NFV e MEC.
Inoltre, si prevede che supporti l'integrazione delle 
apparecchiature di rete ottica e a microonde e che sarà compatibile con altri controller come ONOS, ma anche con istanze multiple di TeraFlow che gestiscono diversi domini, al fine di sfruttare funzionalità avanzate e facilitare l'interoperabilità con altre reti.
\newline A differenza dei controller presentati precedentemente TeraFlow è stato progettato con un'architettura cloud-native, pensata per sfruttare appieno le caratteristiche degli ambienti cloud.
Questo approccio, basato su microservizi containerizzati, garantisce una maggiore flessibilità e capacità di adattamento rispetto ai sistemi tradizionali.
\newline L'uso di container, gestiti tramite Kubernetes, permette di isolare ogni microservizio utilizzando una minore quantità di risorse rispetto alle macchine virtuali (VM).
\newline TeraFlow infatti mira a ottimizzare l'uso delle risorse di rete per migliorare l'efficienza energetica e ridurre i costi operativi.
Ciascun microservizio rappresenta una componente che interagisce attraverso la connessione di rete rendendo il controller disaggregato.
%\newline Ogni container, o componente, ha delle responsabilità specifiche e definisce un microservizio che 
Le componenti principali del sistema sono implementate in Java (solo quelle di Automation e Policy) e Python e l'ambiente è sviluppato presso la sede del CTTC a Barcellona. 
%\newline TeraFlow si propone di affrontare le sfide delle reti moderne attraverso un'architettura innovativa e la collaborazione attiva della comunità. 
%\newline L'obiettivo di TeraFlow è sviluppare un controller   per le reti B5G che automatizzi la gestione della rete e sia in grado di scalare per gestire miliardi di dispositivi.
\newline Alcuni dei requisiti funzionali del controller sono rappresentati da \cite{D22}:
\begin{itemize} 
    \item \textbf{usabilità}: realizzata grazie a un'interfaccia utente web (web UI) che consente la configurazione di servizi predefiniti e visualizzazione personalizzabile delle metriche.
    \item \textbf{scalabilità}: è intrinseca nel design del controller con la replicazione automatica dei miscroservizi per gestire elevati volumi di richieste in ingresso.
    \item \textbf{affidabilità}: garantita attraverso robusti meccanismi di monitoraggio che supervisionano lo stato dei miscroservizi e dei flussi, attivando automaticamente dei processi di ripristino se necessari.
\end{itemize}
%I servizi sono progettati per essere semplici e dettagliati, ciò è reso possibile grazie all'uso di protocolli leggeri.
Dal punto di vista della sicurezza il sistema utilizza un approccio basato sul Machine Learning per la prevenzione e la mitigazione degli attacchi \cite{D41}.
\newline Questo progetto riveste un ruolo chiave nel panorama delle tecnologie 5G, contribuendo a unire diverse università e istituti di ricerca per sviluppare soluzioni all'avanguardia
lavorando con organismi di standardizzazione per garantire l'adozione su scala globale.
%L'architettura è basata su microservizi interconnessi da un bus grpc.
\section{Componenti architetturali}
Le componenti di TeraFlow sono classificate in due categorie; le componenti principali del sistema operativo di rete e le netapp sovrapposte \cite{Component}. 
\begin{figure}[h]
    \centering
   \includegraphics[width=1\textwidth]{architetturatf.png}
    \caption{Architettura di TeraFlow \cite{archtfs}}
    \label{fig:tfs}
\end{figure}
Le componenti del sistema operativo di rete (Network Operating System - NOS) formano la base dell'infrastruttura di TeraFlow, illustrata in Figura \ref{fig:tfs}, offrendo servizi di connettività per infrastrutture di rete programmabili avanzate \cite{Component} %sistema operativo si riferisce al controller e le sue componenti principali-> gestisce e coordina le funzioni di rete
basate su tecnologie come P4 (Programming Protocol-independent Packet Processors), OpenConfig e TAPI (Transport API), che forniscono modalità flessibili per gestire il traffico e le configurazioni di rete.
Una delle componenti principali per questa gestione è quella di Context. Ha il compito di memorizzare topologie, dispositivi, 
collegamenti e servizi in un database No-SQL\cite{D31}. 
Questa componente garantisce la coerenza dei dati gestiti, controllando gli accessi concorrenti dei vari componenti del controller SDN \cite{arttfs},
grazie a una Database API.
\newline Le netapp sono applicazioni che operano sopra il livello del NOS, sfruttando le interfacce di comunicazione, indipendentemente dal linguaggio di programmazione, per interagire con le infrastrutture di rete.
Queste applicazioni possono includere strumenti per il monitoraggio, la gestione della qualità del servizio, e altre funzionalità.
%c'era grpc
\newline TeraFlow fornisce, inoltre, soluzioni di automazione SDN e IBN basate su policy. Nello specifico, TeraFlow Automation sfrutta 
importanti eventi di sistema per realizzare la (ri)configurazione di servizi e dispositivi in modo zero-touch, ossia minimizza l'intervento umano attraverso l'automazione.
Riducendo la necessità di interventi manuali da parte degli operatori vengono ridotte significativamente anche le spese operative \cite{Component}.
\newline Alcune componenti di TeraFlow sono suddivise in livelli di astrazione per facilitare la gestione della rete:
\begin{itemize}
\item Device Level Abstraction: fornisce un'astrazione dei dispositivi fisici presenti, consentendo al controller di interagire con diverse tipologie di hardware.
\item Service Level Abstraction: focalizzato sulla gestione e configurazione dei servizi, questo livello gestisce le interazioni con l'SBI (Southbound Interface) per fornire un'interfaccia unificata.
\item Management Level Abstraction: realizza la gestione complessiva della rete, che include il monitoraggio, il controllo e la manutenzione dei servizi e dei dispositivi gestiti tramite SBI, garantendo un controllo centralizzato dell'infrastruttura.
\end{itemize}
Nelle sezioni successive saranno descritte le componenti maggiormente coinvolte nella gestione degli intenti.
La definizione delle rimanenti si può trovare nella documentazione ufficiale \cite{D32}. 

\section{Gestione degli intenti}
La gestione degli intenti all'interno di un sistema SDN è un processo complesso che si avvale di diverse componenti fondamentali. 
Nella seguente sezione verranno esaminati nel dettaglio i principali moduli responsabili di questa gestione 
evidenziando le modalità di comunicazione tra loro.
Per garantire un'analisi più chiara l'approfondimento è stato suddiviso in vari livelli di astrazione, 
partendo dalla gestione dei dispositivi fino alla descrizione delle politiche finali.
\subsection{Device Level Abstraction}
Il Device Level Abstraction permette l'interazione con i dispositivi presenti all'interno della rete.
\newline Una componente fondamentale per questo livello di astrazione è la componente SBI (Southbound Interface), che permette al controller di gestire diversi tipi di dispositivi, garantendo eterogeneità attraverso il supporto a vari protocolli. 
Il ruolo principale dell'SBI è stabilire e mantenere la connessione con i dispositivi, consentendo così la loro integrazione nell'ecosistema del controller \cite{D32}. 
Dopo aver stabilito la connessione con un determinato dispositivo e aver verificato la disponibilità,
la componente mette a disposizione una API che consente di inviare dinamicamente le configurazioni dal controller al dispositivo in formato JSON.
Queste configurazioni permettono di aggiornare i parametri operativi del dispositivo in base alle politiche di rete definite.
%Il controller provvederà a inserire le giuste entry nelle tabelle degli switch o router pertinenti.
%Per questo viene introdotta la componente di monitoring che servirà da supporto per il Management-level Abstraction.
%che interagisce con la il network equipment attraverso pluggable drivers.
%OpenFlowOpenConfig-based routers
\newline Un'altra componente che fa parte di questo livello è quella di Monitoring il cui compito è %offrire supporto al Management-level
%per l'automazione dei servizi. 
%e per prendere le decisioni in tempo reale sulla base di eventi.
gestire le diverse metriche configurate per i dispositivi e i servizi di rete.
A tale scopo memorizza i dati relativi alle Key Performance Indicators (KPI) selezionate e persiste le informazioni all'interno di un database (Metrics Database).
Questo permette di fornire dati dimensionali con serie temporali visualizzabili su Grafana \cite{grafana}.
Per il corretto funzionamento la componente deve essere in grado di recuperare le metriche da tutti i diversi dispositivi monitorati che,
spesso, implementano protocolli diversi. Per questo motivo sono stati inclusi una serie di sottomoduli che si connettono 
agli elementi monitorati utilizzando i protocolli SBI necessari. %I dati estratti vengono memorizzati nel Metrics Database
\newline Quando un valore KPI registrato supera determinate soglie predefinite, la componente di Monitoring invia una notifica dell'evento 
alla componente che ha
originariamente richiesto il monitoraggio della metrica all'interno del controller.
%Questa API permette al controller di notificare in tempo reale le componenti del sistema (ad esempio, quelle di gestione o sicurezza) sugli eventi critici, consentendo interventi tempestivi e automatizzati \cite{D32}.
\newline Ogni evento è composto da una KPI che identifica la regola a cui si riferisce, un timestamp e un KPIValue che rappresenta il valore della specifica metrica monitorata in tempo reale dalla KPI al momento indicato dal timestamp.
Supponendo che la componente di Monitoring stia monitorando la latenza di un collegamento di rete tramite una KPI denominata "Latency" e che la latenza massima accettabile sia 100ms,
se la latenza supera questa soglia, ad esempio 120ms, si genera un evento così composto: 
\begin{itemize}
    \item KPI: "Latency"
    \item Timestamp: "06-09-2024 14:35:20" (la data e l'ora a cui si è verificato l'evento)
    \item KPIValue: 120 ms
\end{itemize}
che sarà poi gestito dai livelli sovrastanti.
Questa funzione, e quindi la componente stessa, è di supporto al Management-level per garantire l'automazione dei servizi.
Quanto si tratta di gestire topologie più complesse che coinvolgono molti dispositivi è necessario un livello di astrazione superiore per specificare la connessione tra vari end-points
senza la necessità di configurare singolarmente ogni dispositivo. 
A tal fine si introduce il Service Level. 

\subsection{Service Level Abstraction}
Il Service Level è responsabile della creazione e dell'aggiornamento dei servizi di rete.
Questo livello di astrazione permette agli utenti di definire astrazioni specifiche per la connessione tra gli end-points attraverso la componente di Service.
\newline Per svolgere questo compito, la componente si avvale di diverse funzionalità offerte dalle altre parti del sistema.
In particolare, per il calcolo dei percorsi di rete, si affida alla componente PathComp (Path Computation).
Ad esempio, se un intento richiede la creazione di una connessione con una latenza minima tra due nodi specifici, 
la componente invia una richiesta alla PathComp, che calcola il percorso ottimale in vase ai valori della latenza.
Una volta ricevuta la risposta, la componente di Service utilizza uno scheduler per configurare i dispositivi di rete lungo il percorso selezionato, utilizzando le connessioni restituite \cite{D32}. %dalla PathComp 
Le specifiche configurazioni vengono propagate all'interfaccia Southbound (SBI) attraverso dei file JSON, consentendo un'automatizzazione della rete e permettendo di astrarre la complessità del livello sottostante all'utente.
%Un utente può selezionare un path scelto o chiedere al controller di determinarne uno che rispetti determinati requisiti. 
\newline La componente di Service supporta diversi tipi di servizi ed è in grado di utilizzare vari protocolli.
Implementa a tale scopo una Service Handler API che consente agli operatori di rete di definire i comportamenti necessari per ciascun tipo di servizio \cite{D32}.
\begin{itemize}
    \item \textbf{L2-VPN}: servizio per dispositivi OpenConfig
    \item \textbf{L3-VPN}: servizio per dispositivi emulati o OpenConfig con supporto per ACLs
    \item \textbf{Connectivity}: servizio per dispositivi TAPI
    \item \textbf{L2 service Handler}: servizio per dispositivi P4
    \item \textbf{Microwave service Handler}
\end{itemize}
Per la sperimentazione è stato usato il servizio \textit{L2 Service Handler} sviluppato per topologie basate su P4.
Questo utilizza lo stesso servizio di \textit{L2-VPN} ma usa il dispositivo per tradurre le richieste ci connessione in regole di forwarding per la pipeline.
Questa interfaccia implementa solamente due funzioni; \textit{SetEndpoint} per creare o aggiornare un insieme di dispositivi utilizzati dal servizio,
e \textit{DeleteEndpoint} per eliminare le regole di configurazione quando il servizio non è più attivo \cite{D32}. 
%La componente descritta ha al suo interno un blocco gRPC che espone una NBI per consentire l'interazione con le altre componenti del controller.  
%Gestisce i vari servizi inviando richieste di calcolo del percorso alla PathComp e successivamente, grazie a uno scheduler, si occupa di
%configurare i dispositivi in base alle connessioni restituite. Questo permette di astrarre la complessità del livello sottostante all'utente
%in quanto la componente è in grado di tradurre l'intento in un insieme di regole che vengono propagate all'SBI attraverso dei file JSON.
Un'altra componente, già introdotta precedentemente, che fa parte di questo livello è la PathComp. Si occupa di gestire la selezione del percorso tra gli end-points per i servizi di connettività di rete. 
Riceve richieste dalla componente di Service e, interagendo con la componente di Context, recupera le informazioni sulle topologie sottostanti al fine di creare
percorsi che soddisfino i requisiti richiesti.
\newline La PathComp rappresenta un'entità singola e specializzata dove possono essere ospitati diversi algoritmi. Questo permette che qualsiasi nuovo algoritmo utilizzato non impatti su altre componenti del controller.
Per confrontare i percorsi viene utilizzato un algoritmo K-SP dove i k percorsi sono ordinati per numero di passi (hop), ritardo end-to-end e larghezza di banda disponibile sul link più congestionato \cite{D53}. 
%La specifica "regolare" sottolinea che l'algoritmo non tiene conto di ottimizzazioni aggiuntive, come ad esempio la minimizzazione del consumo energetico lungo il percorso, che invece sarebbe un obiettivo nell'approccio comparativo descritto nel documento citato.
%Una volta scelto il percorso viene calcolato il risultato della power path con l'approccio EAR.
%Per astrarre la complessità del livello sottostante all'utente la componente di service è in grado di tradurre l'intento in un insieme di regole che propaga all'SBI (sempre attraverso file JSON)
%cosicchè venga configurato ogni device all'interno del percorso per stabilire la connessione.
\newline Il service layer permette quindi al controller di tradurre gli intenti in regole concrete che vengono poi propagate al livello sottostante.
Tuttavia, da solo non ha la capacità di rispondere dinamicamente agli eventi che si verificano nella rete in tempo reale, come il cambiamento dello stato di un collegamento o di una risorsa di rete. %congestionamento o guasto
Per essere in grado di creare, aggiornare o cancellare i servizi di rete in base a tali eventi è necessario introdurre un ulteriore livello di astrazione che automatizzi queste operazioni: il Management Level Abstraction.

\subsection{Management Level Abstraction}
Il Management Level Abstraction è stato introdotto per consentire l'interazione dinamica con la componente di Service permettendo l'automazione di un servizio in risposta agli eventi provenienti dalla rete.
In altre parole, il sistema non si limita a configurare i dispositivi solo su input manuali o su richiesta esplicita, ma è in grado di adattarsi dinamicamente ai cambiamenti in tempo reale. 
Questo livello consente dunque al controller di reagire rapidamente a eventi come congestioni, guasti o modifiche nella topologia, garantendo che la rete mantenga un alto livello di efficienza e l'intento
specificato come servizio continuo da essere realizzato nella rete. 
%\newline Una delle componenti principali è la componente di Monitoring. Essa ha il compito di raccogliere metriche da diverse componenti
%monitorate attraverso moduli che si interfacciano con i relativi protocolli.
%I dati estratti vengono memorizzati in un Metrics Database che supporta meccanismi di aggregazione per analizzare le informazioni e consente di monitorare l'evoluzione dei dati nel tempo.
%Quando una KPI supera una soglia definita precedentemente, il sistema genera un allarme.
%Questo allarme viene inviato alla componente responsabile della gestione di quel servizio specifico, ossia alla componente che ha originariamente richiesto il monitoraggio della specifica metrica all'interno del controller.
\newline Una componente fondamentale è la componente di Policy che interagisce strettamente con la componente di Monitoring descritta precedentemente.
\newline Si occupa di definire condizioni di politica, associate a un determinato servizio, che possono essere applicate sia a livello di singoli dispositivi che a livello di dominio di rete.
Le politiche possono includere più regole collegate tra loro tramite condizioni logiche di AND/OR \cite{D32}, ognuna delle quali genera una KPI specifica da monitorare.
\newline Ogni regola è composta, oltre che dalla KPI che la identifica, da un operatore numerico di confronto (maggiore, minore o uguale), e da un KPIValue.
Quest'ultimo, in combinazione con l'operatore numerico, definisce l'intervallo di valori accettabili o non accettabili per quella specifica metrica.
\newline Se le regole definite nella politica vengono soddisfatte la componente di Monitoring genera un allarme che viene inviato, in questo caso, alla componente di Policy, che reagisce attivando le azioni predefinite.
Ad esempio, se si verifica un eccesso di latenza, la componente di Policy può attivare il ricalcolo del percorso, o altre azioni correttive, tramite la componente di Service
%Tutte queste regole vengono archiviate nel Metrics Database che fornisce anche l'evoluzione dei dati nel tempo.
%Un'ulteriore componente di questo livello è quella di Monitoring che quando rileva che una condizione impostata in una politica viene soddisfatta (ad esempio, un valore di latenza supera una soglia prestabilita), essa genera un allarme.
%Questo allarme viene inviato alla componente responsabile della gestione di quel servizio o flusso specifico all'interno del controller, che è in grado di eseguire l'azione predefinita specificata nella politica.
%Ad esempio, nel caso di un eccesso di latenza, l'allarme viene inviato alla componente di Service, la quale può poi attivare il ricalcolo del percorso o altre azioni correttive.
consentendo di ripristinare lo stato desiderato.
\newline La componente Policy utilizza il Context Database per identificare quali dispositivi o servizi sono coinvolti nella politica.
Se è stato fornito l'ID del servizio, la componente recupera i dispositivi associati a esso, in caso contrario scansiona una lista di dispositivi per individuare quelli che devono rispettare le regole impostate. 
\newline Una regola di politica può avere vari stati che possono essere rappresentati tramite la macchina a stati in Figura \ref{fig:diagramma}:
\begin{itemize}
    \item \textbf{inserted} (inserita)
    \item \textbf{validated} (convalidata)
    \item \textbf{provisioned} (provvista)
    \item \textbf{actively enforced} (attivamente applicata)
    \item \textbf{failed} (fallita)
    \item \textbf{updated} (aggiornata)
    \item \textbf{removed} (rimossa)
\end{itemize}
\begin{figure}[h]
    \centering
   \includegraphics[width=1\textwidth]{diagramma policy.png}
    \caption{Macchina a stati interna alla componente di policy \cite{D32}}
    \label{fig:diagramma}
\end{figure}
%La componente di policy utilizza inoltre il paradigma publish-subscribe per associare dinamicamente condizioni di politica agli eventi rilevati
%che richiedono azioni immediate.
Grazie all'integrazione tra le componenti di Policy e di Monitoring, TeraFlow ha reso possibile l'associazione delle condizioni di politica con gli allarmi generati dal sistema.
In questo modo può implementare una gestione dinamica della rete 
permettendo di mantenere gli SLA (Service Level Agreements) senza necessitare di interventi manuali continui da parte degli operatori riducendo anche la complessità operativa.
In ambienti su larga scala, come le reti distribuite composte da microservizi, questa capacità di adattamento consente anche di prevenire potenziali criticità, ottimizzando continuamente le risorse di rete.
%Ad esempio, una politica potrebbe stabilire che, se la latenza di rete supera i 50 ms per più di 10 minuti, il sistema deve ricalcolare il percorso per ridurre la congestione. 
%In questo caso, la componente Monitoring rileva l’aumento della latenza, genera un allarme e lo invia alla componente Policy. Quest'ultima, verificando che le condizioni della regola 
%siano soddisfatte, attiva la componente Service per ricalcolare automaticamente il percorso e riconfigurare i dispositivi coinvolti.

%Si occupa di creare un service level agreement (SLA) per uno specifico servizio identificato tramite un id.
%A questo punto verrà creato un evento e si eseguiranno delle azioni prestabilite dal controller fino ai dispositivi per gestire i problemi o cambiare il servizio. 
%Solitamente le azioni contemplano l'interazione con altre componenti al livello inferiore.
%Un'esempio può essere una notifica alla componente di Service che si occuperà di modificare il percorso identificato precedentemente per far rispettare nuovamente i requisiti.

\section{gRPC} \label{grpc}
Per garantire l'interoperabilità tra le diverse componenti, TeraFlow utilizza un bus gRPC (Google Remote Procedure Call \cite{grpc}) come protocollo interno, 
un framework che facilita la comunicazione tra servizi in modo efficiente e preciso. 
%Questo protocollo è stato preferito a REST per la sua capacità più concreta di descrivere le interazioni tra entità in modo efficiente e preciso.
%gRPC sfrutta i Protocol Buffers per definire in modo preciso gli schemi dei messaggi condivisi e scambiati tra le componenti. %,consentendo ai vari servizi di implementare le adeguate funzioni di comunicazione indipendentemente dalla piattaforma e dal linguaggio.
\newline Google Remote Procedure Calls (gRPC\cite{grpc}) è un framework OpenSource sviluppato da Google che si ispira al paradigma RPC (Remote Procedure Call). Permette di
connettere, invocare, operare e fare debug di programmi eterogenei in modo semplice.
\newline E' basato sul protocollo di trasporto HTTP/2 che supporta la comunicazione bidirezionale e il multiplexing delle connessioni.
\newline gRPC include supporto per il bilanciamento del carico, il tracciamento, il controllo dello stato e l'autentificazione\cite{grpcArt3} \cite{grpcArt1}, inoltre
%Inoltre, ha la capacità di supportare alte performance di streaming in modalità push da parte del server, consentendo l'indipendenza basata sul set di dati e definizioni, grazie ai metodi YANG,
%e la compressione di dati binari \cite{grpcArt3}.
consente di definire i servizi, i loro metodi di comunicazione e trasportare messaggi attraverso dei file di descrizione dell'interfaccia detti Protocol Buffer, o più semplicemente file proto.
\newline I file proto sono un meccanismo indipendente dal linguaggio e dalla piattaforma 
e permettono di serializzare le strutture dati in modo più efficiente rispetto a formati come JSON o XML, sia in termini di dimensione dei messaggi che di velocità di elaborazione.
\begin{figure}[h]
    \centering
   \includegraphics[width=1\textwidth]{grpc.png}
    \caption{Funzionamento del protocollo gRPC \cite{librogrpc}}
    \label{fig:grpc}
\end{figure}
In Figura \ref{fig:grpc} viene illustrata l'interazione tra un microservizio e un client tramite gRPC.
\newline Per sviluppare un'applicazione gRPC è necessario definire un'interfaccia dei servizi %Questa contiene informazioni su come il servizio deve essere usato e quali sono i metodi, i parametri e 
%il formato da utilizzare per i messaggi. 
all'interno di un file proto (in Figura \ref{fig:grpc} ProductInfo.proto).
Anche se a prima vista può sembrare un file di testo ordinario, come si può notare in Figura \ref{fig:proto}, in realtà specifica i metodi con i parametri di input e i valori di ritorno.
\begin{figure}[h]
    \centering
   \includegraphics[width=1\textwidth]{file proto.png}
    \caption{Esempio di Protocol Buffer file in TeraFlow \cite{ProtoBuf}}
    \label{fig:proto}
\end{figure}
\newline Una volta definita l'interfaccia è possibile generare il codice per il server (server skeleton) e per il client (client stub) nel linguaggio desiderato usando il compilatore Protobuf \textit{protoc}\cite{librogrpc}.
Ciò permette al client di invocare i metodi definiti da remoto.
\newline Quando il client richiede un servizio gRPC, utilizza i protocol buffer per serializzare la chiamata in un formato compatibile con il protocollo. 
Successivamente, la richiesta è stata inviata tramite HTTP/2 e, una volta ricevuta dal server, viene deserializzata, con il supporto dei Protocol Buffers, per invocare il metodo appropriato.
La risposta segue il flusso inverso da server a client\cite{librogrpc}.
\newline Il framework gRPC semplifica quindi la gestione di aspetti complessi come vincoli di servizio, serializzazione dei dati, comunicazioni di rete e autenticazione.
E' progettato per trasportare messaggi peer-to-peer in modo distribuito e non durevole, consentendo a più servizi di scambiarsi informazioni attraverso un bus condiviso.
Questo lo rende particolarmente adatto per architetture basate su microservizi dove scalabilità e prestazioni sono fondamentali.
Teraflow usa gRPC per la comunicazione tra le componenti e i Protocol Buffers utilizzati sono descritti alla pagina del sito \cite{ProtoBuf}.
\newline Negli esperimenti svolti in \cite{espgrpc} si è dimostrato che gRPC, grazie ai file proto, in scenari che coinvolgono ambienti più complessi con molte componenti (come server, DNS, firewall..)
%the performance in terms of server creation time of an
%orchestration is improved by up to 27\% compared to the traditional REST-based orchestration.
%It is seen that the measures taken to reduce server creation time have proved to be effective. A
%comparison with traditional REST-based orchestration method shows that the gRPC-based
%orchestration method exhibits a reduction of almost up to 27\% in the server creation time that is
%required to create instance and as well as to ensure an instance launch is successful. This
%corresponds to a reduction in total overall execution time.
può portare a una riduzione di quasi il 27\% nel tempo di creazione del server rispetto a REST (Representational State Transfer), uno tra i più moderni e utilizzati sistemi di trasmissione dati, riducendo il tempo di esecuzione complessivo.
Infine, gRPC supporta nativamente TLS (Transport Layer Security), che garantisce la sicurezza delle comunicazioni cifrando i messaggi scambiati tra servizi.
Questo aspetto è cruciale per assicurare la protezione dei dati in sistemi distribuiti e critici.

